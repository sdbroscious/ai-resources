# **Criteria for Selecting Tactical AI Tooling for Developers**

**Technical Capabilities**
* **Modality support** - Evaluate inline suggestions, chat interfaces, and autonomous agent capabilities to match different developer workflows
* **Model support** - Assess which AI models are supported, their capabilities, and update frequency for future-proofing
* **Prompt/instruction support** - Test customization options for tailoring behavior to team standards and project requirements
* **Context awareness & intelligence** - Measure how well the tool understands existing codebase, architectural patterns, and maintains context across files

**Code Quality & Output**
* **Accuracy and relevance** - Evaluate correctness of generated code across your technology stack and complexity levels
* **Security practices** - Assess the tool's ability to suggest secure coding patterns and avoid common vulnerabilities
* **Code augmentation with your codebase** - Test how effectively it learns from and integrates with your existing code patterns and standards

**Integration & Workflow**
* **Cross-IDE support** - Ensure compatibility with your team's preferred development environments
* **Workflow efficiency** - Measure actual impact on developer velocity and integration with existing CI/CD processes
* **Metrics and measurement** - Evaluate available analytics for tracking usage, productivity gains, and code quality improvements

**Enterprise & Operational Readiness**
* **Data security** - Review privacy policies, data handling practices, and compliance with organizational requirements
* **Enterprise admin tools** - Assess user management, policy enforcement, and governance capabilities
* **License costs** - Analyze pricing models, scalability costs, and total cost of ownership
* **Premium requests/usage limits** - Understand rate limits, premium features, and cost scaling factors

**Adoption & Change Management**
* **Learning curve** - Evaluate onboarding time, documentation quality, and skill requirements across different developer experience levels
* **Developer adoption factors** - Consider team dynamics, resistance to change, and alignment with existing practices
* **Vendor support** - Assess community resources, customer support quality, and long-term roadmap alignment

**Recommended Evaluation Process:**
1. **Technical screening** - Use the first three categories to create a shortlist of 2-3 tools
2. **Pilot testing** - Run 2-4 week trials with real projects, measuring both technical performance and developer satisfaction
3. **Enterprise validation** - Conduct thorough security, cost, and administrative capability reviews
4. **Adoption planning** - Develop rollout strategy based on learning curve and change management requirements

This unified approach ensures you evaluate both the technical merit and organizational fit of each tool.

>NOTE: I know I had a genAI tool generate this. But I can't find the prompt.